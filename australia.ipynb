{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshio\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "from ugs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"australia/data/AUS.vtk\"\n",
    "outfile = \"costed_aus.vtk\"\n",
    "mesh = meshio.read(infile)\n",
    "\n",
    "max_distance = 75000  # this is quite a small max_distance. \n",
    "                      # A smaller value means visiting far fewer nodes, so it speeds things up a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to define a way to calculate cost\n",
    "def travel_cost(mesh, current, _next):\n",
    "    # The travel_cost can be any function, including just the distance.\n",
    "    # Here, we exagerate the elevation difference, to make changing elevation more costly\n",
    "    if current == _next:\n",
    "        return 0\n",
    "    \n",
    "    z_scaling = 100.  # 100. is a random number to pick, but has quite a big impact on the resulting paths.\n",
    "    \n",
    "    new_current = np.append(mesh.points[current][:2], mesh.point_data['Z'][current] * z_scaling)\n",
    "    new_next    = np.append(mesh.points[_next][:2],   mesh.point_data['Z'][_next]   * z_scaling)\n",
    "    \n",
    "    return int(np.linalg.norm(new_current - new_next))  # return as Int, just for niceness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for parallel execution\n",
    "\n",
    "We want to use a parallel map function to calculate the cost for all points. We can make this easier by 'baking in' the parameters of a function we know, and leave only the `starting point` as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# We bake in the mesh and travel_cost function into the get_from_point function\n",
    "get_from_point_in_mesh = partial(get_from_point, mesh = mesh, travel_cost_function = travel_cost, max_distance = max_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2087, 4382359)\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the get_from_point function with only a point ID as a parameter, by going via the new get_from_point_in_mesh function\n",
    "# Here we do a test, and see the output format: (point, total cost of all paths to that point)\n",
    "print get_from_point_in_mesh(2087)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input data\n",
    "\n",
    "We don't want to calculate the LEC of a point below sea-level, so here we find all the points above sea-level, so they can be used as starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_above_sealevel = np.nonzero(mesh.point_data['Z'] >= 0)[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total starting points available:  138726\n"
     ]
    }
   ],
   "source": [
    "print \"Total starting points available: \", points_above_sealevel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Output data variables\n",
    "all_costs = []\n",
    "mesh.point_data['cost'] = np.zeros_like(mesh.point_data['Z'])\n",
    "\n",
    "# For parallel execution, we chunk the data up into increments (inc), so we can monitor the progress\n",
    "start = 0\n",
    "inc = 200\n",
    "stop = inc\n",
    "\n",
    "# Run on 11 CPUs\n",
    "p = Pool(11)\n",
    "\n",
    "while start <  points_above_sealevel.shape[0]-1:\n",
    "    start_time = time.time()\n",
    "    # Here we use a parallel map function to send out the chunk across the CPUs in the Pool\n",
    "    costs = p.map(get_from_point_in_mesh, points_above_sealevel[start:stop])\n",
    "    print \"From \", start, \" to \", stop, \" took \", time.time() - start_time, \"seconds, starting with point\", points_above_sealevel[start], \". Percent complete: \", 100*(float(stop)/points_above_sealevel.shape[0])\n",
    "    \n",
    "    # Save the data\n",
    "    all_costs.extend(costs)\n",
    "    \n",
    "    # Write out data progressively, so we can see progress in Paraview\n",
    "    for i in all_costs:\n",
    "        mesh.point_data['cost'][i[0]] = i[1]\n",
    "    meshio.write(outfile, mesh)\n",
    "    \n",
    "    # move to the next chunk of data\n",
    "    start += inc\n",
    "    stop += inc\n",
    "    if stop >= points_above_sealevel.shape[0]:\n",
    "        stop = points_above_sealevel.shape[0]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Output\n",
    "\n",
    "Show some of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print all_costs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
